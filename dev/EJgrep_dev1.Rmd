---
title: "End Joining Signatures - dev"
author: "Charlie Soeder"
date: "2/15/2019"
output: pdf_document
bibliography: references.bib

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(readr)

```



## 25 February 2019

Rebuilding, starting with summary stats for the materials/methods section.


```{r include=FALSE}

human_readable_croncher <- function(num_in) {
	dig <- 3
	num_out <- formatC(num_in, digits=dig, format='g') %>% as.numeric() %>% sitools::f2si()
	return(num_out)
}

bam_summary_loader <- function(filename, aligner="bwa", reference='dm6'){
	
	tmp.df <- read_delim(filename, "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
	names(tmp.df) <- c("sample","measure","value")
	
	tmp.df$sample <- as.factor(tmp.df$sample)
	tmp.df$measure <- as.factor(tmp.df$measure)
	tmp.df$aligner <- as.factor(aligner)
	tmp.df$reference <- as.factor(reference)
	
	return(tmp.df)
	
}




```



```{r include=FALSE}
library("yaml")

trammel <- read_yaml("../config.yaml")

```

Reference genomes 

```{r include=FALSE, echo=FALSE}
library("knitr")
library("tidyverse")

refGenomes_summary_df <- read_delim("meta/reference_genomes.summary", 
    "\t", escape_double = FALSE, col_names = FALSE, 
    trim_ws = TRUE)

names(refGenomes_summary_df) <- c("refGenome","measure","value")

```

```{r echo=FALSE}
refGenomes_summary_df %>% mutate( value=human_readable_croncher(value)) %>% spread(refGenome, value) %>% rename('Reference Genome:'=measure)  %>% kable(caption="Size and Consolidation of Reference Genomes")

```

Sequenced reads



```{r include=FALSE}
data_sets.df <- plyr::ldply(trammel$data_sets, data.frame)
data_sets.df$name <- as.factor(data_sets.df$name)
data_sets.df$paired<- as.factor(data_sets.df$paired)
data_sets.df$experimental<- as.factor(data_sets.df$experimental)
data_sets.df$source<- as.factor(data_sets.df$source)
```


```{r echo=FALSE, results='asis'}
data_sets.df %>% filter(subgroups=='all') %>% group_by(experimental) %>% summarise(sample_count=n()) %>% kable(caption="Number of Sequenced Samples by Treatment")
```



```{r echo=FALSE}
data_sets.df %>% filter(subgroups=='all') %>%  select(c(name, paired, experimental, source)) %>%  arrange(experimental, desc(name)) %>% kable(caption="Sequenced Experimental Samples")
```


```{r echo=FALSE, include=FALSE}
fastp_summary <- read_delim("meta/sequenced_reads.dat", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
names(fastp_summary ) <- c("name","type","measure","value")
fastp_summary$name <- as.factor(fastp_summary$name)
fastp_summary$type <- as.factor(fastp_summary$type)
fastp_summary$measure <- as.factor(fastp_summary$measure)
```



```{r echo=FALSE, include=FALSE}
filtration_stats <- inner_join(fastp_summary %>%  filter(type=="prefiltered" | type == 'postfiltered'), data_sets.df, by=c("name"="name"))
filtration_stats$type <- factor(filtration_stats$type, levels=c("prefiltered", "postfiltered"))
```


Total Starting Reads:  $`r sum( filtration_stats %>% filter(type =='prefiltered') %>%  filter(measure=='total_reads') %>% select(value) ) %>% human_readable_croncher() `$ 
Post-QC Reads:  $`r sum( filtration_stats %>% filter(type =='postfiltered') %>%  filter(measure=='total_reads') %>% select(value) ) %>% human_readable_croncher() `$. 



```{r echo=FALSE}
pre_post_counts <- filtration_stats %>% filter(measure=='total_reads') %>%  group_by(type)  %>%  summarise(minimum = min(value), average=mean(value) , maximum = max(value)) 
retention_percent <- filtration_stats %>% filter(measure=='total_reads') %>%  filter(subgroups=="all")%>% select(c(name,type,value)) %>%  spread(type,value) %>% mutate(retention=100*postfiltered/prefiltered) %>%  summarise(type='percent retention', minimum = min(retention), average=mean(retention) , maximum = max(retention))
```
```{r echo=FALSE}
rbind(pre_post_counts, retention_percent) %>% mutate(minimum = human_readable_croncher(minimum), average=human_readable_croncher(average) , maximum = human_readable_croncher(maximum)) %>% kable(caption="Read Count and Percent Retention")
```


This framework is general-purpose enough that it might be a good template.............

```{r echo=FALSE, include=FALSE}
library("ggbio")
ggplot(filtration_stats %>% filter(measure == "q30_rate")) + geom_line(aes(group=name, x=type,y=100*value)) +  geom_point(aes(x=type, y = 100*value, color=name)) + labs(title = "Percent of Reads with a mean QUAL > 30", y="Percent QUAL > 30", x="") + theme_clear()

```



Dupes:

```{r echo=FALSE, include=FALSE}
dupe_stats <- inner_join(fastp_summary %>% filter(type=='duplication' & measure =='rate') %>%  mutate(percent=value*100) %>% select(c(name,percent)), data_sets.df, by=c("name"="name"))
```

```{r echo=FALSE}
dupe_stats %>%  summarise(minimum = min(percent), average=mean(percent), median=median(percent) , maximum = max(percent)) %>% kable(caption="Percentage Duplication",digits=1)
```

```{r echo=FALSE}
ggplot(dupe_stats) + geom_histogram(aes(x=percent), bins=15) + labs(title="Duplication Histogram", x="Read Duplication Rate (FASTP estimate)", y="Number Samples") + theme_clear()
```

## 27 February 2019

Bioinformatics tips on INDEL calling & normalization with DSB background:

https://genome.sph.umich.edu/w/images/b/b4/Variant_Calling_and_Filtering_for_INDELs.pdf

## 5 March 2019

Going to go ahead and recycle BWA-Uniq but may want to change the algorithm later....


```{r echo=FALSE, include=FALSE}

bam_summary_loader <- function(filename, aligner="bwa", reference='dm6'){
	
	tmp.df <- read_delim(filename, "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
	names(tmp.df) <- c("sample","measure","value")
	
	tmp.df$sample <- as.factor(tmp.df$sample)
	tmp.df$measure <- as.factor(tmp.df$measure)
	tmp.df$aligner <- as.factor(aligner)
	tmp.df$reference <- as.factor(reference)
	
	return(tmp.df)
	
}



vs_dm6.bwa <- bam_summary_loader(filename = "meta/alignments.vs_dm6.bwa.summary",aligner="bwa", reference="dm6")
vs_dm6.bwaUniq <- bam_summary_loader(filename = "meta/alignments.vs_dm6.bwaUniq.summary",aligner="bwaUniq", reference="dm6")

all_alignments <- rbind(vs_dm6.bwa, vs_dm6.bwaUniq)



readcount_process <- all_alignments %>%  filter( (measure=='total_read_count' & aligner=="bwa") | measure == 'total_mapped_count' ) %>% mutate(measure=ifelse(aligner=="bwaUniq", "filtered_mapped_count", ifelse(measure=="total_read_count","total_read_count","total_mapped_count"))) 
readcount_process$measure <- factor(readcount_process$measure, levels = c('total_read_count','total_mapped_count','filtered_mapped_count'))


ggplot(readcount_process) + geom_line(aes(group=sample, x=measure,y=value)) + geom_point(aes(x=measure, y=value, group=sample,color=sample))  + labs(title="Read Counts by Processing Step: Unmapped, Mapped, Filtered", x="", y="Number Reads" ) + scale_y_log10()  + theme_clear() + theme(axis.text.x = element_text(angle = -45, hjust = 0)) 

```



```{r echo=FALSE}

readcount_process.spread <- readcount_process %>% select(-c(aligner)) %>%  spread(measure, value) %>%  mutate(mapping_retention=total_mapped_count/total_read_count, filter_retention = filtered_mapped_count/total_mapped_count)


readcount_process.spread%>% gather(total_read_count:filtered_mapped_count, key="measure", value="value") %>%  group_by(measure) %>% summarise(minimum = min(value), average=mean(value), median = median(value), maximum = max(value)) %>% mutate(minimum = human_readable_croncher(minimum), average=human_readable_croncher(average), median = human_readable_croncher(median), maximum = human_readable_croncher(maximum)) %>% kable(caption="Read Counts During Alignment & Filtration")

```



```{r echo=FALSE}
readcount_process.spread %>% gather(mapping_retention:filter_retention, key="measure", value="value") %>%  group_by(measure) %>% summarise(minimum = min(100*value), average=mean(100*value), median = median(100*value), maximum = max(100*value)) %>% mutate(minimum = human_readable_croncher(minimum), average=human_readable_croncher(average), median = human_readable_croncher(median), maximum = human_readable_croncher(maximum)) %>%  kable(caption="Percentage of Reads Retained at Each Step",digits=1)

```


```{r echo=FALSE, include=FALSE}

before_After.cov <- inner_join( vs_dm6.bwa %>%  filter(measure=='avg_depth' | measure == 'total_breadth') %>% select(-c(aligner)) %>% spread(measure, value), vs_dm6.bwaUniq %>%  filter(measure=='avg_depth' | measure == 'total_breadth') %>% select(-c(aligner)) %>% spread(measure, value), by='sample', suffix=c(".before",".after") ) %>%  mutate(depth_retention = avg_depth.after/avg_depth.before, breadth_retention=total_breadth.after/total_breadth.before)


before_After.cov.gathered.meta <- inner_join(before_After.cov %>%  gather(avg_depth.before:breadth_retention, key="measure", value="value") , data_sets.df, by=c("sample"="name") ) 


```

Depth of coverage:

```{r echo=FALSE}

depth.process <- all_alignments  %>%  filter(measure=='avg_depth' )%>% spread(aligner, value) %>%  mutate(depth_retention = 100*bwaUniq/bwa) %>% rename( "before" = bwa,  "after" = bwaUniq)

covstats.dpth <- depth.process %>% summarise(step="pre-filtration depth",minimum = min(before), average=mean(before), median = median(before), maximum = max(before))

covstats.dpth <- rbind(covstats.dpth, depth.process %>% summarise(step="post-filtration depth",minimum = min(after), average=mean(after), median = median(after), maximum = max(after)))

covstats.dpth <- rbind(covstats.dpth, depth.process  %>% summarise(step="depth retention percent",minimum = min(depth_retention), average=mean(depth_retention), median = median(depth_retention), maximum = max(depth_retention)))

covstats.dpth %>% kable(caption="Depth of Coverage Statistics for Raw and Filtered Alignments", digits=1 )
```

```{r echo=FALSE}
ggplot(depth.process %>%  select(-c(depth_retention,measure)) %>%  gather(before:after, key=measure, value=value) %>% mutate(measure=factor(measure, levels=c("before","after"))) ) +geom_line(aes(group=sample, x=measure,y=value))+ geom_point(aes(group=sample, x=measure,y=value, color=sample)) +  labs(title="Depth Of Coverage for Raw and Filtered Alignments", x="", y="Reads Per BP, Genome-Wide" )


```

Breadth of coverage:

```{r echo=FALSE, include=FALSE}
breadth.process <- all_alignments %>%  filter(measure=='total_breadth' ) %>% spread(aligner, value) %>%  mutate(breadth_retention = 100*bwaUniq/bwa) %>% rename( "before" = bwa, "after" = bwaUniq)

covstats.brdth <- breadth.process %>% summarise(step="pre-filtration breadth",minimum = 100*min(before), average=100*mean(before), median = 100*median(before), maximum = 100*max(before))

covstats.brdth <- rbind(covstats.brdth, breadth.process %>% summarise(step="post-filtration breadth",minimum = 100*min(after), average=100*mean(after), median = 100*median(after), maximum = 100*max(after)))

covstats.brdth <- rbind(covstats.brdth, breadth.process  %>% summarise(step="breadth retention percent",minimum = min(breadth_retention), average=mean(breadth_retention), median = median(breadth_retention), maximum = max(breadth_retention)))

covstats.brdth %>% kable(caption="Breadth of Coverage Statistics for Raw and Filtered Alignments", digits=1 )

```


```{r echo=FALSE, include=FALSE}
ggplot(breadth.process %>%  select(-c(breadth_retention, measure)) %>%  gather(before:after, key=measure, value=value) %>% mutate(measure=factor(measure, levels=c("before","after")), value=100*value) ) + geom_point(aes(group=sample, x=measure,y=value, color=sample)) + geom_line(aes(group=sample, x=measure,y=value)) + labs(title="Depth Of Coverage for Raw and Filtered Alignments", x="", y="Percentage of Reference Genome Mapped To" )

```


Will run the VCF caller on both BWA and BWA-Uniq; reporting will be reworked since we're interested in indels. 

## 5 March 2019

Doing things a little differently, calling variants from both BWA and BWA-Uniq, then compare the two. (whereas before we used reference genome as a variable)


## 6 March 2019


```{r echo=FALSE, include=FALSE}
all_samples.vs_dm6.calledVariants.summary <- read_delim("meta/all_samples.vs_dm6.calledVariants.summary", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
names(all_samples.vs_dm6.calledVariants.summary) <- c("subset", "aligner", "variant_type", "count")
all_samples.vs_dm6.calledVariants.summary$aligner <- as.factor(all_samples.vs_dm6.calledVariants.summary$aligner)
all_samples.vs_dm6.calledVariants.summary$variant_type <- as.factor(all_samples.vs_dm6.calledVariants.summary$variant_type)

reference_genomes_summaryStats.sprud <- refGenomes_summary_df %>%  spread(measure,value) %>%  select(c(-number_contigs)) 

all_samples.vs_dm6.calledVariants.summary.sprud <- all_samples.vs_dm6.calledVariants.summary %>% spread(variant_type, count) %>%  transmute( aligner=aligner, INDELs = total_indel_count, SNPs = total_snp_count) 

all_samples.vs_dm6.calledVariants.summary.sprud$total_bp <- reference_genomes_summaryStats.sprud$number_bases

all_samples.vs_dm6.calledVariants.summary.sprud %>%  transmute( aligner=aligner, INDELs = INDELs, INDEL_per_kb=1000*INDELs/total_bp, SNPs = SNPs, SNP_per_kb=1000*SNPs/total_bp) %>% mutate(INDELs=human_readable_croncher(SNPs), INDELs=human_readable_croncher(SNPs) ) %>%  kable(caption="Breadth of Coverage Statistics for Raw and Filtered Alignments", digits=1 )
```



```{r echo=FALSE, include=FALSE}
all_samples.calledVariants.bwa.lmiss <- read_delim("meta/VCFs/all_samples.vs_dm6.bwa.summary.lmiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples.calledVariants.bwa.lmiss$aligner <- "bwa"

all_samples.calledVariants.bwaUniq.lmiss <- read_delim("meta/VCFs/all_samples.vs_dm6.bwaUniq.summary.lmiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples.calledVariants.bwaUniq.lmiss$aligner <- "bwaUniq"


nsamps <- nrow(data_sets.df %>%  filter(subgroups == 'all') )


all_samples.calledVariants.lmiss <- rbind(all_samples.calledVariants.bwa.lmiss, all_samples.calledVariants.bwaUniq.lmiss) %>% select(c(aligner, N_MISS)) %>%  mutate(aligner=as.factor(aligner), N_PRES=nsamps-N_MISS)

```

```{r echo=FALSE}
ggplot(all_samples.calledVariants.lmiss) + geom_freqpoly(aes(x=N_PRES, group=aligner, color=aligner), bins=nsamps) + scale_x_continuous(name ="Number Samples",limits=c(1,nsamps), breaks =seq(1,nsamps,1)) + theme_clear() + labs(title="Histogram of SNPs by Number of Samples Called At Site", y="Number of Sites")
```





```{r echo=FALSE, include=FALSE}
all_samples.bwa.imiss <- read_delim("meta/VCFs/all_samples.vs_dm6.bwa.summary.imiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples.bwa.imiss$aligner <- "bwa"

all_samples.bwaUniq.imiss <- read_delim("meta/VCFs/all_samples.vs_dm6.bwaUniq.summary.imiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples.bwaUniq.imiss$aligner <- "bwaUniq"

all_samples.imiss  <- rbind(all_samples.bwa.imiss, all_samples.bwaUniq.imiss)  %>%  mutate(name=as.factor(INDV), aligner=as.factor(aligner), N_PRES=N_DATA-N_MISS) %>% select(c( name, N_MISS, N_PRES, F_MISS,aligner))

```

```{r echo=FALSE}


all_samples.imiss.augmented <- inner_join(all_samples.imiss, all_alignments %>%  filter(measure=='total_breadth') %>% select(c(sample,aligner,value)) %>% rename(breadth=value) %>% mutate(breadth = 100*breadth), by=c("name"="sample", "aligner"="aligner"))

all_samples.imiss.augmented <-inner_join(all_samples.imiss.augmented, all_alignments %>%  filter(measure=='avg_depth') %>% select(c(sample,aligner,value)) %>% rename(depth=value), by=c("name"="sample", "aligner"="aligner"))

all_samples.imiss.augmented <- all_samples.imiss.augmented %>%  gather(breadth:depth, key="measure", value="value")

```

```{r echo=FALSE}
ggplot(all_samples.imiss.augmented) + geom_point(aes(x= value, y=1-F_MISS, color=aligner, shape=aligner)) + facet_grid(.~measure, scales="free_x")+ theme_clear() + labs(x="", y="Fraction of SNPs Callable", title="Jointly Called SNPs Callable per Sample, by Breadth and Depth of Coverage")



# + geom_text(data=subset(all_samples.imiss.augmented, 1-F_MISS < 0.75 & measure=="breadth"),aes(value,1-F_MISS,label=name))
```



## 7 March 2019

Might also be good to do a comparison between the two VCFs using vcftools --diff. 

```{bash eval=FALSE }
vcftools --vcf variants/all_samples.vs_dm6.bwa.vcf --diff variants/all_samples.vs_dm6.bwaUniq.vcf --diff-site --out comparisonTest 
```

This complains: 
Error: Cannot determine chromosomal ordering of files, both files must contain the same chromosomes to use the diff functions.
Found chrUn_DS483679v1 in file 1 and chrUn_DS483680v1 in file 2.

Let's try using the --chr command to limit to main-line chromosomes....



```{bash eval=FALSE}
vcftools --vcf variants/all_samples.vs_dm6.bwa.vcf --diff variants/all_samples.vs_dm6.bwaUniq.vcf --diff-site --out comparisonTest --chr chr2L --chr chr2R --chr chr3L --chr chr3R --chr chr4 --chr chrM --chr chrX --chr chrY
```


There is also the --diff-site-discordance flag:

"The MATCHING_ALLELES column tells you if the alleles called in file match exactly at that site (i.e the REF and ALT columns are identical in the two files).
The N_COMMON_CALLED column tells you the number of individuals at that site that were called in both files (i.e. the individuals in the intersection of the two datasets that don't have missing data ./. ).
The N_DISCORD column tells you the number of individuals in the intersection that are discordant at that site." -Adam Auton

https://sourceforge.net/p/vcftools/mailman/message/27128665/


also maybe use  --diff-indv-discordance then compare individual discordance to e.g. breadth reduction upon BAM filtration




Locii variable in A only:
```{bash eval=FALSE}
cat dev/meta/VCFs/comparisonTest.diff.sites | tail -n +2 | awk '{if($3 == 1)print;}' | cut -f 1 | uniq -c > dev/meta/VCFs/comparisonTest.diff.sites.Aonly.count

cat dev/meta/VCFs/comparisonTest.diff.sites | tail -n +2 | awk '{if($3 == 1)print;}' | cut -f 1 | uniq -c | awk '{{sum+=$1}} END {{ print sum,"\ttotal"}}' >> dev/meta/VCFs/comparisonTest.diff.sites.Aonly.count
```

in B only:
```{bash eval=FALSE}
cat dev/meta/VCFs/comparisonTest.diff.sites | tail -n +2 | awk '{if($3 == 2)print;}' | cut -f 1 | uniq -c > dev/meta/VCFs/comparisonTest.diff.sites.Bonly.count

cat dev/meta/VCFs/comparisonTest.diff.sites | tail -n +2 | awk '{if($3 == 2)print;}' | cut -f 1 | uniq -c | awk '{{sum+=$1}} END {{ print sum,"\ttotal"}}' >> dev/meta/VCFs/comparisonTest.diff.sites.Bonly.count

```


Locii variable in both A and B:
```{bash eval=FALSE}
cat dev/meta/VCFs/comparisonTest.diff.sites | tail -n +2 | awk '{if($3 == "B")print;}' | cut -f 1 | uniq -c > dev/meta/VCFs/comparisonTest.diff.sites.covary.count

cat dev/meta/VCFs/comparisonTest.diff.sites | tail -n +2 | awk '{if($3 == "B")print;}' | cut -f 1 | uniq -c | awk '{{sum+=$1}} END {{ print sum,"\ttotal"}}' >> dev/meta/VCFs/comparisonTest.diff.sites.covary.count
```

```{r echo=FALSE}
comparisonTest_diff_both <- read_table2("meta/VCFs/comparisonTest.diff.sites.covary.count", col_names = FALSE)
names(comparisonTest_diff_both) <- c("count","chrom")
comparisonTest_diff_both$vcf <- as.factor("both")

comparisonTest_diff_A <- read_table2("meta/VCFs/comparisonTest.diff.sites.Aonly.count", col_names = FALSE)
names(comparisonTest_diff_A) <- c("count","chrom")
comparisonTest_diff_A$vcf <- as.factor("A")

comparisonTest_diff_B <- read_table2("meta/VCFs/comparisonTest.diff.sites.Bonly.count", col_names = FALSE)
names(comparisonTest_diff_B) <- c("count","chrom")
comparisonTest_diff_B$vcf <- as.factor("B")

comparisonTest_diff <- rbind(comparisonTest_diff_both, comparisonTest_diff_A, comparisonTest_diff_B)
```


https://rstudio-pubs-static.s3.amazonaws.com/13301_6641d73cfac741a59c0a851feb99e98b.html

```{r echo=FALSE}
library("VennDiagram")

grid.newpage()

draw.pairwise.venn(area1=sum(comparisonTest_diff %>% filter(vcf=='A' | vcf == "both") %>% filter(chrom=="total") %>%  select(count)), area2=sum(comparisonTest_diff %>% filter(vcf=='B' | vcf == "both") %>% filter(chrom=="total") %>%  select(count)), cross.area =sum(comparisonTest_diff %>% filter(vcf == "both") %>% filter(chrom=="total") %>%  select(count)), category=c('tomato', 'potato'), fill = c("blue", "red"), alpha = rep(0.5, 2))

```

of the ones in the intersection: 


Locii variable in A and B but with at least one discordant individual:
```{bash eval=FALSE, echo=FALSE}
cat dev/meta/VCFs/comparisonTest.diff.sites |  tail -n +2 | awk '{if($3 == "B")print;}' | awk '{if($6>0)print;}' > dev/meta/VCFs/comparisonTest.diff.sites.discord

cat dev/meta/VCFs/comparisonTest.diff.sites.discord| cut -f 1 | uniq -c > dev/meta/VCFs/comparisonTest.diff.sites.discord.count

cat dev/meta/VCFs/comparisonTest.diff.sites.discord| cut -f 1 | uniq -c | awk '{{sum+=$1}} END {{ print sum,"\ttotal"}}' >>dev/meta/VCFs/comparisonTest.diff.sites.discord.count
```


```{r echo=FALSE}
comparisonTest_diff_discord.count <- read_table2("meta/VCFs/comparisonTest.diff.sites.discord.count", col_names = FALSE)
names(comparisonTest_diff_discord.count) <- c("count","chrom")
comparisonTest_diff_discord.count$vcf <- as.factor("discord")

```

a total of $`r comparisonTest_diff_discord.count %>% filter(chrom=="total") %>%  select(count) `$ sites with at least one discordant individual.

```{r echo=FALSE}

comparisonTest_diff_discord <- read_delim("meta/VCFs/comparisonTest.diff.sites.discord", "\t", escape_double = FALSE, col_names = FALSE,trim_ws = TRUE)
names(comparisonTest_diff_discord) <- c("chrom", "pos", "vcf", "matching", "called", "discord", "disc_rate")


ggplot(comparisonTest_diff_discord) + geom_histogram(aes(x=disc_rate))

```


OK so that's some VCF comparison infrastructure; how to implement? Here we are comparing VCFs from two different alignment/calling strategies but ultimately we'll probably want to compare subgroups of all_samples. Do I use the same rule for both? It's possible that down the line when an alignment/calling strategy is decided upon, I won't want something so general...


## 8 March 2019

Looking at INDELs  within the control subset...
```{bash eval=FALSE}
vcftools --vcf variants/all_samples.vs_dm6.bwaUniq.vcf --keep-only-indels --freq --out test
vcftools --vcf variants/all_samples.vs_dm6.bwaUniq.vcf --keep-only-indels --counts --out test
```

hmmm, we're presumably looking for individual-specific alleles; there could potentially be more than one such allele at a given site! (these show up in the VCF as eg 0/2)

The INDELs .... will they be het or hom??? Presumably Het, since the break repair only happens on one strand....

Finding all the variants from the above count tallies with only one chromosome in the population carrying; awk + grep for more filtration.
```{bash eval=FALSE}
cat test.frq.count | grep -P ':1[$,\t]'
```


## 10 March 2019

Background: Figure 1 of [@McVey2008] and https://en.wikipedia.org/wiki/Non-homologous_end_joining

It looks like NHEJ and MMEJ are prone to forming heterozygous indels near the DSB site. (am i right that MMEJ at least will form flanking indels?)

Are the DSBs random across the genome? What are the odds that the same site would be struck by DSB and repair error twice in the population (ie, 30 flies)? if it's very low, we need to look for indels which are heterozygous for an indel in one individual but homozygous in everyone else.

One data subtelty here is that the called variants are vs the ref genome so the ancestral genotype is presumably the one with the higher (f~1.0 in approx isogenic pop) allele frequency. Thus a reversion to het dm6 reference (0/1) from a population of hom variants (1/1) would be a candidate site. Also, since a site which is different from the reference may later be altered via DSB repair (ie, in a 1/1 population a 1/2 genotype with low AF on 2 is a candidate.)

figs to make:
 * histogram of minor allele frequency for indel variants. Many will have a MinAF of 0 (ie, fixed differences); filter these? others will have a small minAF corresponding to e.g. 1 chromosome in the population.  

if there is a flanking behavior this should be easy to pick out: do a histogram of intrachromsomal distance among variants and then to a freq_poly plot binned by genotype (ie, hom vs het). Look for heterozygotes which are neighbors. 

From [@Miller2016]:
"Drosophila oocytes experience ~11–17 DSBs per meiosis
that are restricted to the euchromatin ... How the position
of these DSBs is determined and their fate (whether they become
COs or NCOs) is poorly understood." also discusses recombinational hotspots; evidence is against them??

Table S2 for crossover sites identified in [@Miller2016]; Table S3 for noncrossover sites.

From Danny Miller 11 Jan 2019:

*First, I called SNPs using GATK. From this output I isolated novel deletions for both chromosome X and 2. I re-wrote this script tonight and re-ran it and found four likely novel deletions that I hadn't seen before:

mcm5-12, chrX:12825436, GAAA deletion 
mcm5-21, chr2R:12737873, A deletion 
mcm5-22, chr2R:8597548, T deletion
mcm5-24, chr2L:21664793, TATATA deletion
*

his main finding: 

*I really expected to find lots of deletions suggesting repair of DSBs via NHEJ, but I didn't. This finding is consistent with the 95-ish single genomes I sequenced from homozygous c3g females where I also failed to find any deletions. *

So, maybe another figure would be deletions vs. the major allele? eg, histogram of indel change in nucleotides. 


## Bibliography

