@article{McVey2008,
abstract = {DNA double-strand breaks are normal consequences of cell division and differentiation and must be repaired faithfully to maintain genome stability. Two mechanistically distinct pathways are known to efficiently repair double-strand breaks: homologous recombination and Ku-dependent non-homologous end joining. Recently, a third, less characterized repair mechanism, named microhomology-mediated end joining (MMEJ), has received increasing attention. MMEJ repairs DNA breaks via the use of substantial microhomology and always results in deletions. Furthermore, it probably contributes to oncogenic chromosome rearrangements and genetic variation in humans. Here, we summarize the genetic attributes of MMEJ from several model systems and discuss the relationship between MMEJ and 'alternative end joining'. We propose a mechanistic model for MMEJ and highlight important questions for future research. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {McVey, Mitch and Lee, Sang Eun},
doi = {10.1016/j.tig.2008.08.007},
eprint = {15334406},
file = {:Users/csoeder/Papers/MMEJ repair of double-strand breaks (director's cut)- deleted sequences and alternative endings.pdf:pdf},
isbn = {0168-9525},
issn = {01689525},
journal = {Trends in Genetics},
number = {11},
pages = {529--538},
pmid = {18809224},
title = {{MMEJ repair of double-strand breaks (director's cut): deleted sequences and alternative endings}},
volume = {24},
year = {2008}
}
@article{Miller2016,
abstract = {A century of genetic analysis has revealed that multiple mechanisms control the distribution of meiotic crossover events. In Drosophila melanogaster, two significant positional controls are interference and the strongly polar centromere effect. Here, we assess the factors controlling the distribution of crossovers (COs) and noncrossover gene conversions (NCOs) along all five major chromosome arms in 196 single meiotic divisions to generate a more detailed understanding of these controls on a genome-wide scale. Analyzing the outcomes of single meiotic events allows us to distinguish among different classes of meiotic recombination. In so doing, we identified 291 NCOs spread uniformly among the five major chromosome arms and 541 COs (including 52 double crossovers and one triple crossover). We find that unlike COs, NCOs are insensitive to the centromere effect and do not demonstrate interference. Although the positions of COs appear to be determined predominately by the long-range influences of interference and the centromere effect, each chromosome may display a different pattern of sensitivity to interference, suggesting that interference may not be a uniform global property. In addition, unbiased sequencing of a large number of individuals allows us to describe the formation of de novo copy number variants, the majority of which appear to be mediated by unequal crossing over between transposable elements. This work has multiple implications for our understanding of how meiotic recombination is regulated to ensure proper chromosome segregation and maintain genome stability.},
author = {Miller, Danny E. and Smith, Clarissa B. and Kazemi, Nazanin Yeganeh and Cockrell, Alexandria J. and Arvanitakis, Alexandra V. and Blumenstiel, Justin P. and Jaspersen, Sue L. and Hawley, R. Scott},
doi = {10.1534/genetics.115.186486},
file = {:Users/csoeder/Papers/Whole-Genome Analysis of Individual Meiotic Events in Drosophila melanogaster Reveals That Noncrossover Gene Conversions Are Insensitive to Interference and the Centromere Effect.pdf:pdf},
issn = {19432631},
journal = {Genetics},
keywords = {Crossing over,Interference,Meiosis,Noncrossover gene conversion,Whole-genome sequencing},
number = {1},
pages = {159--171},
pmid = {26944917},
title = {{Whole-genome analysis of individual meiotic events in Drosophila melanogaster reveals that noncrossover gene conversions are insensitive to interference and the centromere effect}},
volume = {203},
year = {2016}
}
@article{Chen2018,
abstract = {Motivation: Quality control and preprocessing of FASTQ files are essential to providing clean data for downstream analysis. Traditionally, a different tool is used for each operation, such as quality control, adapter trimming, and quality filtering. These tools are often insufficiently fast as most are developed using high level programming languages (e.g., Python and Java) and provide limited multithreading support. Reading and loading data multiple times also renders preprocessing slow and I/O inefficient. Results: We developed fastp as an ultra-fast FASTQ preprocessor with useful quality control and data-filtering features. It can perform quality control, adapter trimming, quality filtering, per read quality cutting, and many other operations with a single scan of the FASTQ data. It also supports unique molecular identifier preprocessing, poly tail trimming, output splitting, and base correction for paired-end data. It can automatically detect adapters for single-end and paired-end FASTQ data. This tool is developed in C++ and has multithreading support. Based on our evaluation, fastp is 2 to 5 times faster than other FASTQ preprocessing tools such as Trimmomatic or Cutadapt despite performing far more operations than similar tools. Availability and Implementation: The open-source code and corresponding instructions are available at https://github.com/OpenGene/fastp},
author = {Chen, Shifu and Zhou, Yanqing and Chen, Yaru and Gu, Jia},
doi = {10.1093/bioinformatics/bty560},
file = {:Users/csoeder/Papers/fastp an ultra-fast all-in-one FASTQ preprocessor.pdf:pdf},
isbn = {9788476662106},
issn = {14602059},
journal = {Bioinformatics},
number = {17},
pages = {i884--i890},
pmid = {23766329},
title = {{Fastp: An ultra-fast all-in-one FASTQ preprocessor}},
volume = {34},
year = {2018}
}
@article{Garrison2012,
abstract = {The direct detection of haplotypes from short-read DNA sequencing data requires changes to existing small-variant detection methods. Here, we develop a Bayesian statistical framework which is capable of modeling multiallelic loci in sets of individuals with non-uniform copy number. We then describe our implementation of this framework in a haplotype-based variant detector, FreeBayes.},
archivePrefix = {arXiv},
arxivId = {1207.3907},
author = {Garrison, Erik and Marth, Gabor},
eprint = {1207.3907},
file = {:Users/csoeder/Library/Application Support/Mendeley Desktop/Downloaded/Garrison, Marth - 2012 - Haplotype-based variant detection from short-read sequencing.pdf:pdf},
month = {jul},
title = {{Haplotype-based variant detection from short-read sequencing}},
url = {http://arxiv.org/abs/1207.3907},
year = {2012}
}
@article{Danecek2011,
abstract = {SUMMARY: The variant call format (VCF) is a generic format for storing DNA polymorphism data such as SNPs, insertions, deletions and structural variants, together with rich annotations. VCF is usually stored in a compressed manner and can be indexed for fast data retrieval of variants from a range of positions on the reference genome. The format was developed for the 1000 Genomes Project, and has also been adopted by other projects such as UK10K, dbSNP and the NHLBI Exome Project. VCFtools is a software suite that implements various utilities for processing VCF files, including validation, merging, comparing and also provides a general Perl API.$\backslash$n$\backslash$nAVAILABILITY: http://vcftools.sourceforge.net},
author = {Danecek, Petr and Auton, Adam and Abecasis, Goncalo and Albers, Cornelis A. and Banks, Eric and DePristo, Mark A. and Handsaker, Robert E. and Lunter, Gerton and Marth, Gabor T. and Sherry, Stephen T. and McVean, Gilean and Durbin, Richard},
doi = {10.1093/bioinformatics/btr330},
file = {:Users/csoeder/Papers/The variant call format and VCFtools.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {15},
pages = {2156--2158},
pmid = {21653522},
title = {{The variant call format and VCFtools}},
volume = {27},
year = {2011}
}
@article{Garrison2012,
abstract = {The direct detection of haplotypes from short-read DNA sequencing data requires changes to existing small-variant detection methods. Here, we develop a Bayesian statistical framework which is capable of modeling multiallelic loci in sets of individuals with non-uniform copy number. We then describe our implementation of this framework in a haplotype-based variant detector, FreeBayes.},
archivePrefix = {arXiv},
arxivId = {1207.3907},
author = {Garrison, Erik and Marth, Gabor},
eprint = {1207.3907},
file = {:Users/csoeder/Library/Application Support/Mendeley Desktop/Downloaded/Garrison, Marth - 2012 - Haplotype-based variant detection from short-read sequencing.pdf:pdf},
month = {jul},
title = {{Haplotype-based variant detection from short-read sequencing}},
url = {http://arxiv.org/abs/1207.3907},
year = {2012}
}
@article{Li2009,
abstract = {MOTIVATION: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals.

RESULTS: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows-Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is approximately 10-20x faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package.

AVAILABILITY: http://maq.sourceforge.net.},
author = {Li, Heng and Durbin, Richard},
doi = {10.1093/bioinformatics/btp324},
file = {:Users/csoeder/Papers/Fast and accurate short read alignment with Burrows–Wheeler transform.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Genomics,Genomics: methods,Sequence Alignment,Sequence Alignment: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Software},
mendeley-groups = {Work/Human deNovo},
month = {jul},
number = {14},
pages = {1754--60},
pmid = {19451168},
title = {{Fast and accurate short read alignment with Burrows-Wheeler transform.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2705234{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {25},
year = {2009}
}
@article{Li2009a,
abstract = {SUMMARY: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. AVAILABILITY: http://samtools.sourceforge.net.},
author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard},
doi = {10.1093/bioinformatics/btp352},
file = {:Users/csoeder/Papers/The Sequence Alignment Map format and SAMtools.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {16},
pages = {2078--2079},
pmid = {19505943},
title = {{The Sequence Alignment/Map format and SAMtools}},
volume = {25},
year = {2009}
}
@article{Quinlan2010,
abstract = {Testing for correlations between different sets of genomic features is a fundamental task in genomics research. However, searching for overlaps between features with existing web-based methods is complicated by the massive datasets that are routinely produced with current sequencing technologies. Fast and flexible tools are therefore required to ask complex questions of these data in an efficient manner.},
author = {Quinlan, Aaron R. and Hall, Ira M.},
doi = {10.1093/bioinformatics/btq033},
file = {:Users/csoeder/Papers/BEDTools- a flexible suite of utilities for comparing genomic features.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {6},
pages = {841--842},
pmid = {20110278},
title = {{BEDTools: A flexible suite of utilities for comparing genomic features}},
volume = {26},
year = {2010}
}
@article{Ye2009,
abstract = {MOTIVATION: There is a strong demand in the genomic community to develop effective algorithms to reliably identify genomic variants. Indel detection using next-gen data is difficult and identification of long structural variations is extremely challenging. RESULTS: We present Pindel, a pattern growth approach, to detect breakpoints of large deletions and medium-sized insertions from paired-end short reads. We use both simulated reads and real data to demonstrate the efficiency of the computer program and accuracy of the results. AVAILABILITY: The binary code and a short user manual can be freely downloaded from http://www.ebi.ac.uk/ approximately kye/pindel/. CONTACT: k.ye@lumc.nl; zn1@sanger.ac.uk.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ye, Kai and Schulz, Marcel H. and Long, Quan and Apweiler, Rolf and Ning, Zemin},
doi = {10.1093/bioinformatics/btp394},
eprint = {NIHMS150003},
file = {:Users/csoeder/Papers/Pindel- a pattern growth approach to detect break points of large deletions and medium sized insertions from paired-end short reads.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {21},
pages = {2865--2871},
pmid = {19561018},
title = {{Pindel: A pattern growth approach to detect break points of large deletions and medium sized insertions from paired-end short reads}},
volume = {25},
year = {2009}
}


